<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>K Means Clustering Algorithm Examples in R using the Alzheimerâ€™s Data</title>
    <meta charset="utf-8" />
    <meta name="author" content="Brian Schetzsle" />
    <script src="libs/header-attrs-2.22/header-attrs.js"></script>
    <link rel="stylesheet" href="slide-style.css" type="text/css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">


class: title-slide



&lt;br&gt;
&lt;br&gt;
.right-panel[ 

# K Means Clustering Algorithm
Examples in R using the Alzheimer's Data
## Brian Schetzsle

]

---

class: middle

### Preparation

Load the `tidyverse` package into your environment and load your data into a variable. The code will look different and depends where you saved your data. The function that performs the K-Means clustering algorithm is built into R, so there are no additional packages necessary.



```r
library(tidyverse)
AD &lt;- readr::read_csv("./data/alzheimer_data.csv")
```

---

### Clusters within data

Let's visualize two continuous and one categorical variable to see if the different levels of our categorical variable tend to cluster across the two continuous variables.


```r
AD %&gt;% 
  select(female, height, weight) %&gt;% 
  mutate(sex = ifelse(female == 0, "Male", "Female")) %&gt;% 
  ggplot() +
  geom_point(aes(x = height, y = weight, color = sex))
```

---

### Clusters within data

&lt;img src="Lab-16-KMeansClustering_files/figure-html/unnamed-chunk-4-1.png" style="display: block; margin: auto;" /&gt;

---

### Normalizing our data

K-Means Clustering, like K-Nearest Neighbor, calculates euclidean distance between points. This means we must first normalize the continuous variables to be meaningfully compared (this is also why categorical variables can't be used). In this context normalizing means subtracting the minimum value and dividing by the range of values in the data so each variable is in the range [0,1]. I have also seen data "standardized", which means subtracting the mean and dividing by the standard deviation.

$$
\frac{X_i - min(X)}{max(X) - min(X)}
$$

---

### Normalizing our data


```r
AD_subset &lt;- AD %&gt;% 
  select(height, weight) %&gt;% 
  apply(2, function(x){(x - min(x))/(max(x)-min(x))}) %&gt;% 
  data.frame() %&gt;% 
  mutate(sex = ifelse(AD$female == 0, "Male", "Female"))
```

---

### Normalizing our data


```r
AD_subset %&gt;% 
  ggplot() +
  geom_point(aes(x = height, 
                 y = weight, 
                 color = sex))
```

---

### Normalizing our data

&lt;img src="Lab-16-KMeansClustering_files/figure-html/unnamed-chunk-7-1.png" style="display: block; margin: auto;" /&gt;

---

### Seperating our data into Training and Testing subsets

I don't think there's a reason why you would do this.

---

### Running the K Means Clustering Algorithm


```r
model &lt;- AD_subset %&gt;% 
  select(height, weight) %&gt;% 
  kmeans(centers = 2, nstart = 20)

AD_subset &lt;- AD_subset %&gt;% 
  mutate(cluster = model$cluster)

AD_subset %&gt;% 
  group_by(sex, cluster) %&gt;% 
  summarise(n = n()) %&gt;% 
  reshape2::dcast(sex ~ cluster)
```

```
##      sex    1   2
## 1 Female 1232 317
## 2   Male  242 909
```

---

### Plotting the Clustered Data


```r
AD_subset %&gt;% 
  ggplot() +
  geom_point(aes(x = height, y = weight, 
                 color = factor(cluster) ))
```

---

### Plotting the Clustered Data

&lt;img src="Lab-16-KMeansClustering_files/figure-html/unnamed-chunk-10-1.png" style="display: block; margin: auto;" /&gt;

---

### Plotting the Clustered Data

&lt;img src="Lab-16-KMeansClustering_files/figure-html/unnamed-chunk-11-1.png" style="display: block; margin: auto;" /&gt;
---

### Determining a Good Value for K

Now let's expand our focus to include more variables and naively cluster the data. How do we know what K to specify? We could run the algorithm on a range of K and see if there is a value that accounts for a noteworthy drop in sum of squared distances from the nearest centroid.


```r
AD_subset &lt;- AD %&gt;% 
  select(age, educ, height, weight, 
         bpsys, bpdias, hrate) %&gt;% 
  apply(2, function(x){(x - min(x))/(max(x)-min(x))}) %&gt;% 
  data.frame()
```

---

### Clustering the Data


```r
# Decide how many clusters to look at
n_clusters &lt;- 10

# Initialize the total sum of squared distances
ss &lt;- numeric(n_clusters)

# Look over 1 to n possible clusters
for (i in 1:n_clusters) {
  model &lt;- kmeans(AD_subset, centers = i, 
                  nstart = 20, iter.max = 20)
  # Save the within cluster sum of squares
  ss[i] &lt;- model$tot.withinss
}
```

---

### Evaluating the Performance of Different Ks


```r
data.frame(K = 1:n_clusters, ss = ss) %&gt;% 
  ggplot(aes(x = K, y = ss)) +
  geom_point(size = 4) +
  geom_line() +
  ggtitle("Scree Plot") +
  xlab("Number of Clusters") +
  scale_x_continuous(breaks = seq(0,10,2))
```

---

### Evaluating the Performance of Different Ks

It doesn't look like there's a noteable drop in the sum of squared distances from the nearest centroid for any particular value of K. Let's work with K=3.

&lt;img src="Lab-16-KMeansClustering_files/figure-html/unnamed-chunk-15-1.png" style="display: block; margin: auto;" /&gt;



---

### Cluster the Data using K=3


```r
model &lt;- kmeans(AD_subset, centers = 3, nstart = 20)
AD_subset &lt;- AD_subset %&gt;% 
  mutate(cluster = model$cluster)
```

---

### Evaluate the Characteristics of Each Cluster


```r
AD_subset %&gt;% 
  ggplot() +
  geom_density(aes(x = age, fill = as.factor(cluster)), 
               alpha=0.5)
```

&lt;img src="Lab-16-KMeansClustering_files/figure-html/unnamed-chunk-17-1.png" style="display: block; margin: auto;" /&gt;

---

### Evaluate the Characteristics of Each Cluster


```r
AD_subset %&gt;% 
  ggplot() +
  geom_density(aes(x = weight, fill = as.factor(cluster)), 
               alpha=0.5)
```

&lt;img src="Lab-16-KMeansClustering_files/figure-html/unnamed-chunk-18-1.png" style="display: block; margin: auto;" /&gt;

---

### Evaluate the Characteristics of Each Cluster


```r
AD_subset %&gt;% 
  ggplot() +
  geom_density(aes(x = height, fill = as.factor(cluster)), 
               alpha=0.5)
```

&lt;img src="Lab-16-KMeansClustering_files/figure-html/unnamed-chunk-19-1.png" style="display: block; margin: auto;" /&gt;

---

### Evaluate the Characteristics of Each Cluster


```r
AD_subset %&gt;% 
  ggplot() +
  geom_point(aes(x = age, y = educ, 
                 color = factor(cluster)))
```

&lt;img src="Lab-16-KMeansClustering_files/figure-html/unnamed-chunk-20-1.png" style="display: block; margin: auto;" /&gt;

---

### Practice

- Choose a subset of your continuous variables and normalize them
- Choose a K
- Cluster your normalized data
- Visualize the results
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="cols_macro.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "pygments",
"highlightLines": true,
"highlightLanguage": "r"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
